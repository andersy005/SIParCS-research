
<!DOCTYPE html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      <meta http-equiv="x-ua-compatible" content="ie=edge">
      
      
        <link rel="canonical" href="https://ncar.github.io/PySpark4Climate/installation/cheyenne/">
      
      
      
        <link rel="shortcut icon" href="../../images/favicon.ico">
      
      <meta name="generator" content="mkdocs-0.16.3, mkdocs-material-1.7.4">
    
    
      
        <title>Cheyenne - PySpark for Climate</title>
      
    
    
      <script src="../../assets/javascripts/modernizr-1df76c4e58.js"></script>
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/application-769c285a91.css">
      
        <link rel="stylesheet" href="../../assets/stylesheets/application-02c2a4388f.palette.css">
      
    
    
      
        
        
        
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700|Roboto+Mono">
        <style>body,input{font-family:"Roboto","Helvetica Neue",Helvetica,Arial,sans-serif}code,kbd,pre{font-family:"Roboto Mono","Courier New",Courier,monospace}</style>
      
      <link rel="stylesheet" href="https://fonts.googleapis.com/icon?family=Material+Icons">
    
    
    
  </head>
  
  
  
  
    <body data-md-color-primary="green" data-md-color-accent="green">
  
    <svg class="md-svg">
      <defs>
        
        
          <svg xmlns="http://www.w3.org/2000/svg" width="416" height="448" viewBox="0 0 416 448" id="github"><path fill="currentColor" d="M160 304q0 10-3.125 20.5t-10.75 19T128 352t-18.125-8.5-10.75-19T96 304t3.125-20.5 10.75-19T128 256t18.125 8.5 10.75 19T160 304zm160 0q0 10-3.125 20.5t-10.75 19T288 352t-18.125-8.5-10.75-19T256 304t3.125-20.5 10.75-19T288 256t18.125 8.5 10.75 19T320 304zm40 0q0-30-17.25-51T296 232q-10.25 0-48.75 5.25Q229.5 240 208 240t-39.25-2.75Q130.75 232 120 232q-29.5 0-46.75 21T56 304q0 22 8 38.375t20.25 25.75 30.5 15 35 7.375 37.25 1.75h42q20.5 0 37.25-1.75t35-7.375 30.5-15 20.25-25.75T360 304zm56-44q0 51.75-15.25 82.75-9.5 19.25-26.375 33.25t-35.25 21.5-42.5 11.875-42.875 5.5T212 416q-19.5 0-35.5-.75t-36.875-3.125-38.125-7.5-34.25-12.875T37 371.5t-21.5-28.75Q0 312 0 260q0-59.25 34-99-6.75-20.5-6.75-42.5 0-29 12.75-54.5 27 0 47.5 9.875t47.25 30.875Q171.5 96 212 96q37 0 70 8 26.25-20.5 46.75-30.25T376 64q12.75 25.5 12.75 54.5 0 21.75-6.75 42 34 40 34 99.5z"/></svg>
        
      </defs>
    </svg>
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="drawer">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="search">
    <label class="md-overlay" data-md-component="overlay" for="drawer"></label>
    
      <header class="md-header" data-md-component="header">
  <nav class="md-header-nav md-grid">
    <div class="md-flex">
      <div class="md-flex__cell md-flex__cell--shrink">
        
          <a href="https://ncar.github.io/PySpark4Climate/" title="PySpark for Climate" class="md-logo md-header-nav__button">
            <img src="../../images/NCAR_50.png" width="24" height="24">
          </a>
        
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        <label class="md-icon md-icon--menu md-header-nav__button" for="drawer"></label>
      </div>
      <div class="md-flex__cell md-flex__cell--stretch">
        <span class="md-flex__ellipsis md-header-nav__title">
          
            
              
                <span class="md-header-nav__parent">
                  Installation
                </span>
              
            
            Cheyenne
          
        </span>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        
          <label class="md-icon md-icon--search md-header-nav__button" for="search"></label>
          
<div class="md-search" data-md-component="search">
  <label class="md-search__overlay" for="search"></label>
  <div class="md-search__inner">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" required placeholder="Search" accesskey="s" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="query">
      <label class="md-icon md-search__icon" for="search"></label>
      <button type="reset" class="md-icon md-search__icon" data-md-component="reset">close</button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="result" data-md-lang-search="">
          <div class="md-search-result__meta" data-md-lang-result-none="No matching documents" data-md-lang-result-one="1 matching document" data-md-lang-result-other="# matching documents">
            Type to start searching
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
        
      </div>
      
        <div class="md-flex__cell md-flex__cell--shrink">
          <div class="md-header-nav__source">
            


  


  <a href="https://github.com/NCAR/PySpark4Climate" title="Go to repository" class="md-source" data-md-source="github">
    
      <div class="md-source__icon">
        <svg viewBox="0 0 24 24" width="24" height="24">
          <use xlink:href="#github" width="24" height="24"></use>
        </svg>
      </div>
    
    <div class="md-source__repository">
      GitHub
    </div>
  </a>

          </div>
        </div>
      
    </div>
  </nav>
</header>
    
    <div class="md-container">
      
      
      <main class="md-main">
        <div class="md-main__inner md-grid" data-md-component="container">
          
            
              <div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    <nav class="md-nav md-nav--primary" data-md-level="0">
  <label class="md-nav__title md-nav__title--site" for="drawer">
    
      <i class="md-logo md-nav__button">
        <img src="../../images/NCAR_50.png">
      </i>
    
    PySpark for Climate
  </label>
  
    <div class="md-nav__source">
      


  


  <a href="https://github.com/NCAR/PySpark4Climate" title="Go to repository" class="md-source" data-md-source="github">
    
      <div class="md-source__icon">
        <svg viewBox="0 0 24 24" width="24" height="24">
          <use xlink:href="#github" width="24" height="24"></use>
        </svg>
      </div>
    
    <div class="md-source__repository">
      GitHub
    </div>
  </a>

    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      


  <li class="md-nav__item">
    <a href="../.." title="Home" class="md-nav__link">
      Home
    </a>
  </li>

    
      
      
      

  


  <li class="md-nav__item md-nav__item--active md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-2" type="checkbox" id="nav-2" checked>
    
    <label class="md-nav__link" for="nav-2">
      Installation
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-2">
        Installation
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../yellowstone/" title="Yellowstone" class="md-nav__link">
      Yellowstone
    </a>
  </li>

        
          
          
          

  


  <li class="md-nav__item md-nav__item--active">
    
    <input class="md-toggle md-nav__toggle" data-md-toggle="toc" type="checkbox" id="toc">
    
      
    
    
      <label class="md-nav__link md-nav__link--active" for="toc">
        Cheyenne
      </label>
    
    <a href="./" title="Cheyenne" class="md-nav__link md-nav__link--active">
      Cheyenne
    </a>
    
      
<nav class="md-nav md-nav--secondary">
  
  
    
  
  
    <label class="md-nav__title" for="toc">Table of contents</label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#1-installation" title="1. Installation" class="md-nav__link">
    1. Installation
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#11-downloading-spark-and-setting-up-sparks-directory-and-necessary-files" title="1.1 Downloading Spark and Setting up Spark's directory and necessary files" class="md-nav__link">
    1.1 Downloading Spark and Setting up Spark's directory and necessary files
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#12-scripts" title="1.2 Scripts" class="md-nav__link">
    1.2 Scripts
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#2-running-existing-cheyenne-spark-installation" title="2. Running Existing Cheyenne Spark Installation" class="md-nav__link">
    2. Running Existing Cheyenne Spark Installation
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#21-run-pyspark-shell" title="2.1. Run PySpark Shell" class="md-nav__link">
    2.1. Run PySpark Shell
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#22-run-pyspark-in-a-jupyter-notebook" title="2.2. Run PySpark in a Jupyter notebook" class="md-nav__link">
    2.2. Run PySpark in a Jupyter notebook
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
      
      
    </ul>
  
</nav>
    
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-3" type="checkbox" id="nav-3">
    
    <label class="md-nav__link" for="nav-3">
      Usage
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-3">
        Usage
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../usage/yellowstone/" title="Yellowstone" class="md-nav__link">
      Yellowstone
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../usage/cheyenne/" title="Cheyenne" class="md-nav__link">
      Cheyenne
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-4" type="checkbox" id="nav-4">
    
    <label class="md-nav__link" for="nav-4">
      PySpark4Climate Package
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-4">
        PySpark4Climate Package
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../pyspark4climate/intro/" title="Introduction" class="md-nav__link">
      Introduction
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../pyspark4climate/getting-started/" title="Getting Started" class="md-nav__link">
      Getting Started
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              <div class="md-sidebar md-sidebar--secondary" data-md-component="toc">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    
<nav class="md-nav md-nav--secondary">
  
  
    
  
  
    <label class="md-nav__title" for="toc">Table of contents</label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#1-installation" title="1. Installation" class="md-nav__link">
    1. Installation
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#11-downloading-spark-and-setting-up-sparks-directory-and-necessary-files" title="1.1 Downloading Spark and Setting up Spark's directory and necessary files" class="md-nav__link">
    1.1 Downloading Spark and Setting up Spark's directory and necessary files
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#12-scripts" title="1.2 Scripts" class="md-nav__link">
    1.2 Scripts
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#2-running-existing-cheyenne-spark-installation" title="2. Running Existing Cheyenne Spark Installation" class="md-nav__link">
    2. Running Existing Cheyenne Spark Installation
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#21-run-pyspark-shell" title="2.1. Run PySpark Shell" class="md-nav__link">
    2.1. Run PySpark Shell
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#22-run-pyspark-in-a-jupyter-notebook" title="2.2. Run PySpark in a Jupyter notebook" class="md-nav__link">
    2.2. Run PySpark in a Jupyter notebook
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
      
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content">
            <article class="md-content__inner md-typeset">
              
                
                  <a href="https://github.com/NCAR/PySpark4Climate/edit/master/docs/installation/cheyenne.md" title="Edit this page" class="md-icon md-content__icon">edit</a>
                
                
                <h1 id="apache-spark-211-on-cheyenne">Apache Spark 2.1.1 on Cheyenne<a class="headerlink" href="#apache-spark-211-on-cheyenne" title="Permanent link">&para;</a></h1>
<p>The Second task of our research project was to install the newest version of Apache Spark on Cheyenne. </p>
<p>As of today (June/2017), we've been able to install the newest version of Apache Spark - <a href="https://spark.apache.org/downloads.html">Spark 2.1.1+Hadoop2.7</a>.</p>
<p>Below are the steps that we took to get Spark Up and Running on Cheyenne.</p>
<p>If all you need is to run the existing Apache Spark on Cheyenne, just skip to <strong>Section 2</strong> of this page.</p>
<h2 id="1-installation">1. Installation<a class="headerlink" href="#1-installation" title="Permanent link">&para;</a></h2>
<h3 id="11-downloading-spark-and-setting-up-sparks-directory-and-necessary-files">1.1 Downloading Spark and Setting up Spark's directory and necessary files<a class="headerlink" href="#11-downloading-spark-and-setting-up-sparks-directory-and-necessary-files" title="Permanent link">&para;</a></h3>
<p>The steps described in this section are similar to those for Yellowstone. Since both Yellowstone and Cheyenne have access to the same parallel filesytem, we decide to use the same downloaded Spark binaries.</p>
<p>The following section gives details on how Apache Spark would be installed on Cheyenne.</p>
<ol>
<li>Log into Cheyenne</li>
<li>Change working directory to <code class="codehilite">/glade/p/work/abanihi</code><ul>
<li><code class="codehilite">cd /glade/p/work/abanihi/</code></li>
</ul>
</li>
<li>
<p>Go to <a href="https://spark.apache.org/downloads.html">Apache Spark's official website</a> and follow steps 1-4 to get a download link for Spark. Copy the download link and </p>
</li>
<li>
<p>Go to <code class="codehilite">/glade/p/work/abanihi/</code> and download Spark</p>
<ul>
<li><code class="codehilite">wget https://d3kbcqa49mib13.cloudfront.net/spark-2.1.1-bin-hadoop2.7.tgz</code></li>
<li>Untar <code class="codehilite">spark-2.1.1-bin-hadoop2.7.tgz</code> with <ul>
<li><code class="codehilite">tar -xzf spark-2.1.1-bin-hadoop2.7.tgz</code></li>
</ul>
</li>
</ul>
</li>
<li>
<p>Change directory to <code class="codehilite">spark-2.1.1-bin-hadoop2.7/conf</code> and open <code class="codehilite">log4j.properties.template</code></p>
<ul>
<li><code class="codehilite">cd spark-2.1.1-bin-hadoop2.7/conf</code></li>
<li><code class="codehilite">nano log4j.properties.template</code></li>
<li>Go to the following line: <code class="codehilite">log4j.rootCategory=INFO, console</code> and change <code class="codehilite">INFO</code> to <code class="codehilite">ERROR</code></li>
<li>Exit out of the editor</li>
</ul>
</li>
<li>
<p>Rename <code class="codehilite">log4j.properties.template</code> to <code class="codehilite">log4j.properties</code></p>
<ul>
<li><code class="codehilite">mv log4j.properties.template log4.properties</code></li>
</ul>
</li>
<li>
<p>Change working directory to <code class="codehilite">/glade/p/work/abanihi</code></p>
<ul>
<li><code class="codehilite">cd /glade/p/work/abanihi/</code></li>
</ul>
</li>
<li>
<p>Download H5Spark Package: This package supports Hierarchical Data Format, HDF5/netCDF4 and Rich Parallel I/O interface in Spark. For more details, please see this <a href="https://github.com/NCAR/PySpark4Climate/blob/devel/docs/templates/h5spark.md">page</a>.</p>
<ul>
<li><code class="codehilite">git clone https://github.com/valiantljk/h5spark.git</code></li>
<li>This package will be added to <code class="codehilite">Python Path</code> in <code class="codehilite">spark-cluster.sh</code> script.</li>
</ul>
</li>
</ol>
<h3 id="12-scripts">1.2 Scripts<a class="headerlink" href="#12-scripts" title="Permanent link">&para;</a></h3>
<p>Even though the scripts for Yellowstone and Cheyenne have so much in common, there are some differences.</p>
<ul>
<li>
<p>Change working directory to <code class="codehilite">/glade/p/work/abanihi</code></p>
<ul>
<li><code class="codehilite">cd /glade/p/work/abanihi</code></li>
</ul>
</li>
<li>
<p>Create a new directory called <code class="codehilite">cheyenne</code> and move into it </p>
<ul>
<li><code class="codehilite">mkdir cheyenne</code></li>
<li><code class="codehilite">`cd cheyenne</code></li>
<li>Create <code class="codehilite">spark-cluster-scripts</code>directory and move into it</li>
<li><code class="codehilite">mkdir spark-cluster-scripts</code></li>
<li><code class="codehilite">cd spark-cluster-scripts/</code></li>
</ul>
</li>
<li>
<p>Create a new script and name it <code class="codehilite">spark-env.sh</code></p>
<ul>
<li><code class="codehilite">nano spark-env.sh</code></li>
<li><code class="codehilite">spark-env.sh</code> should have the following content </li>
</ul>
</li>
</ul>
<div class="codehilite"><pre><span></span><span class="c1">##!/usr/bin/env bash</span>

<span class="nb">source</span> /etc/profile.d/modules.sh

module restore system
module swap intel gnu
<span class="nb">export</span> <span class="nv">MODULEPATH</span><span class="o">=</span>/glade/p/work/bdobbins/Modules:<span class="si">${</span><span class="nv">MODULEPATH</span><span class="si">}</span>
module load java
ml python
ml numpy
ml jupyter
ml scipy
ml h5py
ml bottleneck
ml numexpr
ml pandas
ml pyside
ml matplotlib
ml pyngl
ml scikit-learn
ml netcdf4-python
ml cf_units
ml xarray

<span class="nb">export</span> <span class="nv">SPARK_WORKER_DIR</span><span class="o">=</span>/glade/scratch/<span class="nv">$USER</span>/spark/work
<span class="nb">export</span> <span class="nv">SPARK_LOG_DIR</span><span class="o">=</span>/glade/scratch/<span class="nv">$USER</span>/spark/logs
<span class="nb">export</span> <span class="nv">SPARK_LOCAL_DIRS</span><span class="o">=</span>/glade/scratch/<span class="nv">$USER</span>/spark/temp
<span class="nb">export</span> <span class="nv">SPARK_LOCAL_IP</span><span class="o">=</span><span class="k">$(</span>sed -e <span class="s1">&#39;s/\([^.]*\).*$/\1/&#39;</span> <span class="o">&lt;&lt;&lt;</span> <span class="k">$(</span>hostname<span class="k">))</span>
</pre></div>

<ul>
<li>Create a new script file and name it <code class="codehilite">spark-cluster.sh</code><ul>
<li><code class="codehilite">nano spark-cluster.sh</code></li>
</ul>
</li>
</ul>
<div class="codehilite"><pre><span></span><span class="ch">#!/usr/bin/env bash</span>
<span class="nb">export</span> <span class="nv">SPARK_HOME</span><span class="o">=</span>/glade/p/work/abanihi/spark-2.1.1-bin-hadoop2.7/
<span class="nb">export</span> <span class="nv">PYTHONPATH</span><span class="o">=</span><span class="nv">$SPARK_HOME</span>/python/:<span class="nv">$PYTHONPATH</span>
<span class="nb">export</span> <span class="nv">PYTHONPATH</span><span class="o">=</span><span class="nv">$PYTHONPATH</span>:/glade/p/work/abanihi/h5spark/src/main/python/h5spark/:<span class="nv">$PYTHONPATH</span>
<span class="nb">export</span> <span class="nv">SPARK_CONF_DIR</span><span class="o">=</span>~/cheyenne/spark/conf
<span class="nb">export</span> <span class="nv">SPARK_HOSTFILE</span><span class="o">=</span><span class="nv">$SPARK_CONF_DIR</span>/spark_hostfile

<span class="c1"># create temp hostfile</span>
<span class="nb">export</span> <span class="nv">SPARK_TEMP_HOSTFILE</span><span class="o">=</span><span class="nv">$SPARK_CONF_DIR</span>/spark_temp_hostfile

rm <span class="nv">$SPARK_HOSTFILE</span> <span class="nv">$SPARK_CONF_DIR</span>/slaves

<span class="nb">export</span> <span class="nv">MPI_SHEPHERD</span><span class="o">=</span><span class="nb">true</span>
mpiexec_mpt hostname <span class="p">|</span> grep -v Execute <span class="p">|</span> sort &gt;&gt; <span class="nv">$SPARK_TEMP_HOSTFILE</span>

<span class="c1">#sed -i &#39;s/$/-ib/&#39; $SPARK_TEMP_HOSTFILE</span>
cat <span class="nv">$SPARK_TEMP_HOSTFILE</span> <span class="p">|</span> sort -u &gt;&gt; <span class="nv">$SPARK_HOSTFILE</span>
tail -n +2 <span class="nv">$SPARK_TEMP_HOSTFILE</span> <span class="p">|</span> sort -u &gt;&gt; <span class="nv">$SPARK_CONF_DIR</span>/slaves
tail -n +2 <span class="nv">$SPARK_TEMP_HOSTFILE</span> <span class="p">|</span> uniq -c &gt; temp_ncores_slaves

rm <span class="nv">$SPARK_TEMP_HOSTFILE</span>


<span class="nb">export</span> <span class="nv">SPARK_MASTER_HOST</span><span class="o">=</span><span class="k">$(</span>head -n <span class="m">1</span> <span class="nv">$SPARK_HOSTFILE</span><span class="k">)</span>
<span class="nb">export</span> <span class="nv">MASTER</span><span class="o">=</span>spark://<span class="nv">$SPARK_MASTER_HOST</span>:7077

cp spark-env.sh <span class="nv">$SPARK_CONF_DIR</span>/spark-env.sh
<span class="nb">source</span> <span class="nv">$SPARK_CONF_DIR</span>/spark-env.sh

<span class="k">if</span> <span class="o">[</span> <span class="s2">&quot;</span><span class="nv">$1</span><span class="s2">&quot;</span> <span class="o">==</span> <span class="s2">&quot;start&quot;</span> <span class="o">]</span><span class="p">;</span> <span class="k">then</span>
    <span class="nv">cmd_master</span><span class="o">=</span><span class="s2">&quot;</span><span class="nv">$SPARK_HOME</span><span class="s2">/sbin/start-master.sh&quot;</span>
    <span class="nv">cmd_slave</span><span class="o">=</span><span class="s2">&quot;</span><span class="nv">$SPARK_HOME</span><span class="s2">/sbin/spark-daemon.sh --config </span><span class="nv">$SPARK_CONF_DIR</span><span class="s2"> start org.apache.spark.deploy.worker.Worker 1 </span><span class="nv">$MASTER</span><span class="s2">&quot;</span>
<span class="k">elif</span> <span class="o">[</span> <span class="s2">&quot;</span><span class="nv">$1</span><span class="s2">&quot;</span> <span class="o">==</span> <span class="s2">&quot;stop&quot;</span> <span class="o">]</span><span class="p">;</span> <span class="k">then</span>
    <span class="nv">cmd_master</span><span class="o">=</span><span class="s2">&quot;</span><span class="nv">$SPARK_HOME</span><span class="s2">/sbin/stop-master.sh&quot;</span>
    <span class="nv">cmd_slave</span><span class="o">=</span><span class="s2">&quot;</span><span class="nv">$SPARK_HOME</span><span class="s2">/sbin/spark-daemon.sh --config </span><span class="nv">$SPARK_CONF_DIR</span><span class="s2"> stop org.apache.spark.deploy.worker.Worker 1&quot;</span>
<span class="k">else</span>
    <span class="nb">exit</span> <span class="m">1</span>
<span class="k">fi</span>

<span class="nv">$cmd_master</span>

<span class="k">while</span> <span class="nb">read</span> ncore_slave
<span class="k">do</span>
    <span class="nv">ncore</span><span class="o">=</span><span class="k">$(</span><span class="nb">echo</span> <span class="nv">$ncore_slave</span> <span class="p">|</span> cut -d<span class="s1">&#39; &#39;</span> -f1<span class="k">)</span>
    <span class="nv">slave</span><span class="o">=</span><span class="k">$(</span><span class="nb">echo</span> <span class="nv">$ncore_slave</span> <span class="p">|</span> cut -d<span class="s1">&#39; &#39;</span> -f2<span class="k">)</span>

    <span class="k">if</span> <span class="o">[</span> <span class="s2">&quot;</span><span class="nv">$slave</span><span class="s2">&quot;</span> <span class="o">==</span> <span class="s2">&quot;</span><span class="nv">$SPARK_MASTER_HOST</span><span class="s2">&quot;</span> <span class="o">]</span><span class="p">;</span> <span class="k">then</span>
          <span class="nb">echo</span> <span class="s2">&quot;On Master node.  Running: cmd_slave --cores </span><span class="nv">$ncore</span><span class="s2">&quot;</span>
          <span class="nv">$cmd_slave</span> --cores <span class="nv">$ncore</span>
     <span class="k">else</span>
          <span class="nb">echo</span> <span class="s2">&quot;On Worker node.  Running: cmd_slave --cores </span><span class="nv">$ncore</span><span class="s2">&quot;</span>
          ssh <span class="nv">$slave</span> <span class="s2">&quot;</span><span class="nv">$cmd_slave</span><span class="s2">&quot;</span> --cores <span class="nv">$ncore</span> &lt; /dev/null

    <span class="k">fi</span>
<span class="k">done</span> &lt;temp_ncores_slaves
</pre></div>

<ul>
<li>Create a new script file and name it <code class="codehilite">start-pyspark.sh</code></li>
</ul>
<div class="codehilite"><pre><span></span><span class="ch">#!/usr/bin/env bash</span>

<span class="nb">source</span> spark-cluster.sh start
<span class="nv">$SPARK_HOME</span>/bin/pyspark --master <span class="nv">$MASTER</span>
</pre></div>

<ul>
<li>Create a new script file and name it <code class="codehilite">start-sparknotebook</code>. This script file is an extension of <code class="codehilite">/glade/apps/opt/jupyter/5.0.0/gnu/4.8.2/bin/start-notebook</code> script file.</li>
</ul>
<div class="codehilite"><pre><span></span><span class="ch">#!/usr/bin/env bash</span>

<span class="nb">source</span> spark-cluster.sh start

<span class="c1"># Add the PySpark classes to the Python path:</span>
<span class="nb">export</span> <span class="nv">PATH</span><span class="o">=</span><span class="s2">&quot;</span><span class="nv">$SPARK_HOME</span><span class="s2">:</span><span class="nv">$PATH</span><span class="s2">&quot;</span>
<span class="nb">export</span> <span class="nv">PATH</span><span class="o">=</span><span class="nv">$PATH</span>:<span class="nv">$SPARK_HOME</span>/bin
<span class="nb">export</span> <span class="nv">PYTHONPATH</span><span class="o">=</span><span class="nv">$SPARK_HOME</span>/python/:<span class="nv">$PYTHONPATH</span>
<span class="nb">export</span> <span class="nv">PYTHONPATH</span><span class="o">=</span><span class="nv">$SPARK_HOME</span>/python/lib/py4j-0.10.4-src.zip:<span class="nv">$PYTHONPATH</span>

<span class="c1"># Create trap to kill notebook when user is done</span>
kill_server<span class="o">()</span> <span class="o">{</span>
    <span class="k">if</span> <span class="o">[[</span> <span class="s2">&quot;</span><span class="nv">$JNPID</span><span class="s2">&quot;</span> !<span class="o">=</span> -1 <span class="o">]]</span><span class="p">;</span> <span class="k">then</span>
        <span class="nb">echo</span> -en <span class="s2">&quot;\nKilling Jupyter Notebook Server with PID=</span><span class="nv">$JNPID</span><span class="s2"> ... &quot;</span>
        <span class="nb">kill</span> <span class="s2">&quot;</span><span class="nv">$JNPID</span><span class="s2">&quot;</span>
        <span class="nb">echo</span> <span class="s2">&quot;done&quot;</span>
        <span class="nb">exit</span> <span class="m">0</span>
    <span class="k">else</span>
        <span class="nb">exit</span> <span class="m">1</span>
    <span class="k">fi</span>
<span class="o">}</span>

<span class="nv">JNPID</span><span class="o">=</span>-1
<span class="nb">trap</span> kill_server SIGHUP SIGINT SIGTERM

<span class="c1"># Begin server creation</span>
<span class="nv">JNHOST</span><span class="o">=</span><span class="k">$(</span>hostname<span class="k">)</span>
<span class="nv">LOGDIR</span><span class="o">=</span>/glade/scratch/<span class="si">${</span><span class="nv">USER</span><span class="si">}</span>/.jupyter-notebook
<span class="nv">LOGFILE</span><span class="o">=</span><span class="si">${</span><span class="nv">LOGDIR</span><span class="si">}</span>/log.<span class="k">$(</span>date +%Y%m%dT%H%M%S<span class="k">)</span>
mkdir -p <span class="s2">&quot;</span><span class="nv">$LOGDIR</span><span class="s2">&quot;</span>

<span class="k">if</span> <span class="o">[[</span> <span class="nv">$JNHOST</span> <span class="o">==</span> ch* <span class="o">||</span> <span class="nv">$JNHOST</span> <span class="o">==</span> r* <span class="o">]]</span><span class="p">;</span> <span class="k">then</span>
    <span class="nv">STHOST</span><span class="o">=</span>cheyenne
<span class="k">else</span>
    <span class="nv">STHOST</span><span class="o">=</span>yellowstone
<span class="k">fi</span>

<span class="nb">echo</span> <span class="s2">&quot;Logging this session in </span><span class="nv">$LOGFILE</span><span class="s2">&quot;</span>

<span class="c1"># Check if running on login nodes</span>
<span class="k">if</span> <span class="o">[[</span> <span class="nv">$JNHOST</span> <span class="o">==</span> yslogin* <span class="o">]]</span><span class="p">;</span> <span class="k">then</span>
cat <span class="s">&lt;&lt; EOF</span>

<span class="s">See &quot;Use of login nodes&quot; here before running Jupyter Notebook on this</span>
<span class="s">node: https://www2.cisl.ucar.edu/resources/yellowstone/using_resources.</span>

<span class="s">Consider running on Geyser instead by using execgy to start a session. (Run execgy -help.)</span>
<span class="s">EOF</span>
<span class="k">elif</span> <span class="o">[[</span> <span class="nv">$JNHOST</span> <span class="o">==</span> cheyenne* <span class="o">]]</span><span class="p">;</span> <span class="k">then</span>
cat <span class="s">&lt;&lt; EOF</span>

<span class="s">See &quot;Use of login nodes&quot; here before running Jupyter Notebook on this</span>
<span class="s">node: https://www2.cisl.ucar.edu/resources/computational-systems/cheyenne/running-jobs.</span>

<span class="s">Consider running in an interactive job instead by using qinteractive. (Run qinterative -help.)</span>
<span class="s">EOF</span>
<span class="k">fi</span>


jupyter notebook <span class="s2">&quot;</span><span class="nv">$@</span><span class="s2">&quot;</span> --no-browser --ip<span class="o">=</span><span class="s2">&quot;</span><span class="nv">$JNHOST</span><span class="s2">&quot;</span>&gt; <span class="s2">&quot;</span><span class="nv">$LOGFILE</span><span class="s2">&quot;</span> <span class="m">2</span>&gt;<span class="p">&amp;</span><span class="m">1</span> <span class="p">&amp;</span>
<span class="nv">JNPID</span><span class="o">=</span><span class="nv">$!</span>


<span class="nb">echo</span> -en  <span class="s2">&quot;\nStarting jupyter notebook server, please wait ... &quot;</span>

<span class="nv">ELAPSED</span><span class="o">=</span><span class="m">0</span>
<span class="nv">ADDRESS</span><span class="o">=</span>

<span class="k">while</span> <span class="o">[[</span> <span class="nv">$ADDRESS</span> !<span class="o">=</span> *<span class="s2">&quot;</span><span class="si">${</span><span class="nv">JNHOST</span><span class="si">}</span><span class="s2">&quot;</span>* <span class="o">]]</span><span class="p">;</span> <span class="k">do</span>
    sleep <span class="m">1</span>
    <span class="nv">ELAPSED</span><span class="o">=</span><span class="k">$((</span>ELAPSED+1<span class="k">))</span>
    <span class="nv">ADDRESS</span><span class="o">=</span><span class="k">$(</span>tail -n <span class="m">1</span> <span class="s2">&quot;</span><span class="nv">$LOGFILE</span><span class="s2">&quot;</span><span class="k">)</span>

    <span class="k">if</span> <span class="o">[[</span> <span class="nv">$ELAPSED</span> -gt <span class="m">30</span> <span class="o">]]</span><span class="p">;</span> <span class="k">then</span>
        <span class="nb">echo</span> -e <span class="s2">&quot;something went wrong\n---&quot;</span>
        cat <span class="s2">&quot;</span><span class="nv">$LOGFILE</span><span class="s2">&quot;</span>
        <span class="nb">echo</span> <span class="s2">&quot;---&quot;</span>

        kill_server
    <span class="k">fi</span>
<span class="k">done</span>

<span class="nb">echo</span> -e <span class="s2">&quot;done\n---\n&quot;</span>

<span class="nv">ADDRESS</span><span class="o">=</span><span class="si">${</span><span class="nv">ADDRESS</span><span class="p">##*:</span><span class="si">}</span>
<span class="nv">PORT</span><span class="o">=</span><span class="si">${</span><span class="nv">ADDRESS</span><span class="p">%/*</span><span class="si">}</span>
<span class="nv">TOKEN</span><span class="o">=</span><span class="si">${</span><span class="nv">ADDRESS</span><span class="p">#*=</span><span class="si">}</span>

cat <span class="s">&lt;&lt; EOF</span>
<span class="s">Run the following command on your desktop or laptop:</span>

<span class="s">   ssh -N -l $USER -L 8888:${JNHOST}:$PORT ${STHOST}.ucar.edu</span>

<span class="s">Log in with your YubiKey/Cryptocard (there will be no prompt).</span>
<span class="s">Then open a browser and go to http://localhost:8888. The Jupyter web</span>
<span class="s">interface will ask you for a token. Use the following:</span>

<span class="s">    $TOKEN</span>

<span class="s">Note that anyone to whom you give the token can access (and modify/delete)</span>
<span class="s">files in your GLADE spaces, regardless of the file permissions you</span>
<span class="s">have set. SHARE TOKENS RARELY AND WISELY!</span>

<span class="s">Run the following commands on your destop or latptop:</span>

<span class="s">   ssh -N -l $USER -L 8080:${JNHOST}:8080 ${STHOST}.ucar.edu</span>
<span class="s">   ssh -N -l $USER -L 4040:${JNHOST}:4040 ${STHOST}.ucar.edu</span>

<span class="s">Log in with your YubiKey/Cryptocard(there will be no prompt).</span>
<span class="s">Then open a browser and go to http://localhost:8080 to access the Spark Master UI.</span>

<span class="s">Finally open a browser and go to http://localhost:4040 to access the Spark Master UI jobs</span>
<span class="s">history.</span>

<span class="s">To stop the server, press Ctrl-C.</span>
<span class="s">EOF</span>

<span class="c1"># Wait for user kill command</span>
sleep inf
</pre></div>

<p><strong>Note:</strong> Make the above scripts executable by running (<code class="codehilite">chmod +x script_name.sh</code>)</p>
<h2 id="2-running-existing-cheyenne-spark-installation">2. Running Existing Cheyenne Spark Installation<a class="headerlink" href="#2-running-existing-cheyenne-spark-installation" title="Permanent link">&para;</a></h2>
<ul>
<li>Log into Cheyenne</li>
<li>
<p>Create a working directory in your home and move into it:</p>
<ul>
<li><code class="codehilite">mkdir cheyenne</code></li>
<li><code class="codehilite">`cd cheyenne</code></li>
<li><code class="codehilite">mkdir spark</code></li>
<li><code class="codehilite">cd spark</code></li>
</ul>
</li>
<li>
<p>Copy <code class="codehilite">spark-cluster-scripts</code> directory to <code class="codehilite">spark</code> directory</p>
<ul>
<li><code class="codehilite">cp -r /glade/p/work/abanihi/cheyenne/spark-cluster-scripts .</code></li>
</ul>
</li>
<li>
<p>In the created <code class="codehilite">spark</code> directory, create <code class="codehilite">conf</code> directory:</p>
<ul>
<li><code class="codehilite">mkdir conf</code></li>
</ul>
</li>
<li>
<p>Schedule your job to run on the Cheyenne, by submitting your job through <strong>pbs scheduler</strong></p>
<ul>
<li>Example: <code class="codehilite">qsub -I -l select=4:ncpus=1:mpiprocs=1 -l walltime=00:30:00 -q regular -A ProjectID</code></li>
</ul>
</li>
<li>
<p>Change current directory to <code class="codehilite">spark-cluster-scripts</code></p>
<ul>
<li><code class="codehilite">cd spark-cluster-scripts</code></li>
</ul>
</li>
</ul>
<h3 id="21-run-pyspark-shell">2.1. Run PySpark Shell<a class="headerlink" href="#21-run-pyspark-shell" title="Permanent link">&para;</a></h3>
<ul>
<li>To run PySpark shell, run <code class="codehilite">start-pyspark.sh</code> by running <code class="codehilite">./start-pyspark.sh</code>. You should get something similar to this:<img alt="" src="https://i.imgur.com/cdns3KT.jpg" /></li>
</ul>
<h3 id="22-run-pyspark-in-a-jupyter-notebook">2.2. Run PySpark in a Jupyter notebook<a class="headerlink" href="#22-run-pyspark-in-a-jupyter-notebook" title="Permanent link">&para;</a></h3>
<ul>
<li>
<p>To run PySpark in a Jupyter notebook, make sure you that your current directory is <code class="codehilite">spark-cluster-scripts</code> and </p>
<ul>
<li>run <code class="codehilite">start-sparknotebook</code> by typing <code class="codehilite">./start-sparknotebook</code> and follow the instructions given.</li>
</ul>
</li>
<li>
<p>There are two notebooks in the <code class="codehilite">spark-cluster-scripts/</code> directory. Run the <strong>Spark-Essentials</strong> notebook to test that Spark is running and that you have access to a cluster of nodes.</p>
</li>
</ul>
                
                  
                
              
              
                
              
            </article>
          </div>
        </div>
      </main>
      
        
<footer class="md-footer">
  
    <div class="md-footer-nav">
      <nav class="md-footer-nav__inner md-grid">
        
          <a href="../yellowstone/" title="Yellowstone" class="md-flex md-footer-nav__link md-footer-nav__link--prev" rel="prev">
            <div class="md-flex__cell md-flex__cell--shrink">
              <i class="md-icon md-icon--arrow-back md-footer-nav__button"></i>
            </div>
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
              <span class="md-flex__ellipsis">
                <span class="md-footer-nav__direction">
                  Previous
                </span>
                Yellowstone
              </span>
            </div>
          </a>
        
        
          <a href="../../usage/yellowstone/" title="Yellowstone" class="md-flex md-footer-nav__link md-footer-nav__link--next" rel="next">
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
              <span class="md-flex__ellipsis">
                <span class="md-footer-nav__direction">
                  Next
                </span>
                Yellowstone
              </span>
            </div>
            <div class="md-flex__cell md-flex__cell--shrink">
              <i class="md-icon md-icon--arrow-forward md-footer-nav__button"></i>
            </div>
          </a>
        
      </nav>
    </div>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-footer-copyright">
        
        powered by
        <a href="http://www.mkdocs.org" title="MkDocs">MkDocs</a>
        and
        <a href="http://squidfunk.github.io/mkdocs-material/" title="Material for MkDocs">
          Material for MkDocs</a>
      </div>
      
        
      
    </div>
  </div>
</footer>
      
    </div>
    
      <script src="../../assets/javascripts/application-c35428f87f.js"></script>
      
      
      <script>app.initialize({url:{base:"../.."}})</script>
      
    
    
      
    
  </body>
</html>