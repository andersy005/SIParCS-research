
<!DOCTYPE html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      <meta http-equiv="x-ua-compatible" content="ie=edge">
      
      
        <link rel="canonical" href="https://ncar.github.io/PySpark4Climate/">
      
      
      
        <link rel="shortcut icon" href="./images/favicon.ico">
      
      <meta name="generator" content="mkdocs-0.16.3, mkdocs-material-1.7.4">
    
    
      
        <title>PySpark for Climate</title>
      
    
    
      <script src="./assets/javascripts/modernizr-1df76c4e58.js"></script>
    
    
      <link rel="stylesheet" href="./assets/stylesheets/application-769c285a91.css">
      
        <link rel="stylesheet" href="./assets/stylesheets/application-02c2a4388f.palette.css">
      
    
    
      
        
        
        
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700|Roboto+Mono">
        <style>body,input{font-family:"Roboto","Helvetica Neue",Helvetica,Arial,sans-serif}code,kbd,pre{font-family:"Roboto Mono","Courier New",Courier,monospace}</style>
      
      <link rel="stylesheet" href="https://fonts.googleapis.com/icon?family=Material+Icons">
    
    
    
  </head>
  
  
  
  
    <body data-md-color-primary="green" data-md-color-accent="green">
  
    <svg class="md-svg">
      <defs>
        
        
          <svg xmlns="http://www.w3.org/2000/svg" width="416" height="448" viewBox="0 0 416 448" id="github"><path fill="currentColor" d="M160 304q0 10-3.125 20.5t-10.75 19T128 352t-18.125-8.5-10.75-19T96 304t3.125-20.5 10.75-19T128 256t18.125 8.5 10.75 19T160 304zm160 0q0 10-3.125 20.5t-10.75 19T288 352t-18.125-8.5-10.75-19T256 304t3.125-20.5 10.75-19T288 256t18.125 8.5 10.75 19T320 304zm40 0q0-30-17.25-51T296 232q-10.25 0-48.75 5.25Q229.5 240 208 240t-39.25-2.75Q130.75 232 120 232q-29.5 0-46.75 21T56 304q0 22 8 38.375t20.25 25.75 30.5 15 35 7.375 37.25 1.75h42q20.5 0 37.25-1.75t35-7.375 30.5-15 20.25-25.75T360 304zm56-44q0 51.75-15.25 82.75-9.5 19.25-26.375 33.25t-35.25 21.5-42.5 11.875-42.875 5.5T212 416q-19.5 0-35.5-.75t-36.875-3.125-38.125-7.5-34.25-12.875T37 371.5t-21.5-28.75Q0 312 0 260q0-59.25 34-99-6.75-20.5-6.75-42.5 0-29 12.75-54.5 27 0 47.5 9.875t47.25 30.875Q171.5 96 212 96q37 0 70 8 26.25-20.5 46.75-30.25T376 64q12.75 25.5 12.75 54.5 0 21.75-6.75 42 34 40 34 99.5z"/></svg>
        
      </defs>
    </svg>
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="drawer">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="search">
    <label class="md-overlay" data-md-component="overlay" for="drawer"></label>
    
      <header class="md-header" data-md-component="header">
  <nav class="md-header-nav md-grid">
    <div class="md-flex">
      <div class="md-flex__cell md-flex__cell--shrink">
        
          <a href="https://ncar.github.io/PySpark4Climate/" title="PySpark for Climate" class="md-logo md-header-nav__button">
            <img src="./images/NCAR_50.png" width="24" height="24">
          </a>
        
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        <label class="md-icon md-icon--menu md-header-nav__button" for="drawer"></label>
      </div>
      <div class="md-flex__cell md-flex__cell--stretch">
        <span class="md-flex__ellipsis md-header-nav__title">
          
            
              
            
            Home
          
        </span>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        
          <label class="md-icon md-icon--search md-header-nav__button" for="search"></label>
          
<div class="md-search" data-md-component="search">
  <label class="md-search__overlay" for="search"></label>
  <div class="md-search__inner">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" required placeholder="Search" accesskey="s" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="query">
      <label class="md-icon md-search__icon" for="search"></label>
      <button type="reset" class="md-icon md-search__icon" data-md-component="reset">close</button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="result" data-md-lang-search="">
          <div class="md-search-result__meta" data-md-lang-result-none="No matching documents" data-md-lang-result-one="1 matching document" data-md-lang-result-other="# matching documents">
            Type to start searching
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
        
      </div>
      
        <div class="md-flex__cell md-flex__cell--shrink">
          <div class="md-header-nav__source">
            


  


  <a href="https://github.com/NCAR/PySpark4Climate" title="Go to repository" class="md-source" data-md-source="github">
    
      <div class="md-source__icon">
        <svg viewBox="0 0 24 24" width="24" height="24">
          <use xlink:href="#github" width="24" height="24"></use>
        </svg>
      </div>
    
    <div class="md-source__repository">
      GitHub
    </div>
  </a>

          </div>
        </div>
      
    </div>
  </nav>
</header>
    
    <div class="md-container">
      
      
      <main class="md-main">
        <div class="md-main__inner md-grid" data-md-component="container">
          
            
              <div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    <nav class="md-nav md-nav--primary" data-md-level="0">
  <label class="md-nav__title md-nav__title--site" for="drawer">
    
      <i class="md-logo md-nav__button">
        <img src="./images/NCAR_50.png">
      </i>
    
    PySpark for Climate
  </label>
  
    <div class="md-nav__source">
      


  


  <a href="https://github.com/NCAR/PySpark4Climate" title="Go to repository" class="md-source" data-md-source="github">
    
      <div class="md-source__icon">
        <svg viewBox="0 0 24 24" width="24" height="24">
          <use xlink:href="#github" width="24" height="24"></use>
        </svg>
      </div>
    
    <div class="md-source__repository">
      GitHub
    </div>
  </a>

    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  


  <li class="md-nav__item md-nav__item--active">
    
    <input class="md-toggle md-nav__toggle" data-md-toggle="toc" type="checkbox" id="toc">
    
      
    
    
      <label class="md-nav__link md-nav__link--active" for="toc">
        Home
      </label>
    
    <a href="." title="Home" class="md-nav__link md-nav__link--active">
      Home
    </a>
    
      
<nav class="md-nav md-nav--secondary">
  
  
    
  
  
    <label class="md-nav__title" for="toc">Table of contents</label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#background" title="Background" class="md-nav__link">
    Background
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#goal" title="Goal" class="md-nav__link">
    Goal
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#whats-apache-spark" title="What's Apache Spark?" class="md-nav__link">
    What's Apache Spark?
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#porting-apache-spark-software-stack-on-hpc" title="Porting Apache Spark software stack on HPC" class="md-nav__link">
    Porting Apache Spark software stack on HPC
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#data-in-spark" title="Data in Spark" class="md-nav__link">
    Data in Spark
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#data-in-hdfnetcdf" title="Data in HDF/netCDF" class="md-nav__link">
    Data in HDF/netCDF
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#support-hdfnetcdf-in-spark-2x-series" title="Support HDF/netCDF in Spark 2.x Series" class="md-nav__link">
    Support HDF/netCDF in Spark 2.x Series
  </a>
  
</li>
      
      
      
    </ul>
  
</nav>
    
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-2" type="checkbox" id="nav-2">
    
    <label class="md-nav__link" for="nav-2">
      Installation
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-2">
        Installation
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="installation/yellowstone/" title="Yellowstone" class="md-nav__link">
      Yellowstone
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="installation/cheyenne/" title="Cheyenne" class="md-nav__link">
      Cheyenne
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-3" type="checkbox" id="nav-3">
    
    <label class="md-nav__link" for="nav-3">
      Usage
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-3">
        Usage
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="usage/yellowstone/" title="Yellowstone" class="md-nav__link">
      Yellowstone
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="usage/cheyenne/" title="Cheyenne" class="md-nav__link">
      Cheyenne
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-4" type="checkbox" id="nav-4">
    
    <label class="md-nav__link" for="nav-4">
      PySpark4Climate Package
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-4">
        PySpark4Climate Package
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="pyspark4climate/intro/" title="Introduction" class="md-nav__link">
      Introduction
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="pyspark4climate/getting-started/" title="Getting Started" class="md-nav__link">
      Getting Started
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              <div class="md-sidebar md-sidebar--secondary" data-md-component="toc">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    
<nav class="md-nav md-nav--secondary">
  
  
    
  
  
    <label class="md-nav__title" for="toc">Table of contents</label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#background" title="Background" class="md-nav__link">
    Background
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#goal" title="Goal" class="md-nav__link">
    Goal
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#whats-apache-spark" title="What's Apache Spark?" class="md-nav__link">
    What's Apache Spark?
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#porting-apache-spark-software-stack-on-hpc" title="Porting Apache Spark software stack on HPC" class="md-nav__link">
    Porting Apache Spark software stack on HPC
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#data-in-spark" title="Data in Spark" class="md-nav__link">
    Data in Spark
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#data-in-hdfnetcdf" title="Data in HDF/netCDF" class="md-nav__link">
    Data in HDF/netCDF
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#support-hdfnetcdf-in-spark-2x-series" title="Support HDF/netCDF in Spark 2.x Series" class="md-nav__link">
    Support HDF/netCDF in Spark 2.x Series
  </a>
  
</li>
      
      
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content">
            <article class="md-content__inner md-typeset">
              
                
                  <a href="https://github.com/NCAR/PySpark4Climate/edit/master/docs/index.md" title="Edit this page" class="md-icon md-content__icon">edit</a>
                
                
                <h1 id="pyspark-for-big-atmospheric-oceanic-data-analysis">PySpark for "Big" Atmospheric &amp; Oceanic Data Analysis<a class="headerlink" href="#pyspark-for-big-atmospheric-oceanic-data-analysis" title="Permanent link">&para;</a></h1>
<h2 id="background">Background<a class="headerlink" href="#background" title="Permanent link">&para;</a></h2>
<blockquote>
<p>Climate and Weather directly impact all aspects of society. Understanding these processeses provide important information for policy - and decision - makers. To understand the average climate conditions and extreme weather events, Earth science and climate change researchers need data from climate models and observations. As such in the typical work flow of climate change and atmospheric research, much time is wasted waiting to reformat and regrid data to homogeneous formats. Additionally, because of the data volume, in order to compute metrics, perform analysis, and visualize data / generate plots, multi-stage processes with repeated I/O are used - the root cause of performance bottlenecks and the resulting user’s frustrations related to time inefficiencies.
<strong><a href="https://scispark.jpl.nasa.gov/about.html">NASA-SciSpark project</a></strong></p>
</blockquote>
<p><a name="footnote1">1</a>: Spark is a cluster computing paradigm based on the MapReduce paradigm that has garnered many scientific analysis workflows and are very well suited for Spark.  As a result of this lack of great deal of interest for its power and ease of use in analyzing “big data” in the commercial and computer science sectors.  In much of the scientific sector, however --- and specifically in the atmospheric and oceanic sciences --- Spark has not captured the interest of scientists for analyzing their data, even though their datasets may be larger than many commercial datasets interest, there are very few platforms on which scientists can experiment with and learn about using Hadoop and/or Spark for their scientific research.  Additionally, there are very few resources to teach and educate scientists on how or why to use Hadoop or Spark for their analysis.</p>
<h2 id="goal">Goal<a class="headerlink" href="#goal" title="Permanent link">&para;</a></h2>
<p><strong>PySpark for Big Atmospheric &amp; Oceanic Data Analysis</strong> is a <a href="https://www2.cisl.ucar.edu/siparcs">CISL/SIParCS research project</a> that seeks to explore the realm of distributed parallel computing on NCAR's Yellowstone and Cheyenne supercomputers by taking advantage of: </p>
<ul>
<li>
<p>Apache Spark's potential to offer speed-up and advancements of nearly 1000x in-memory</p>
</li>
<li>
<p>The increasing growing community around Spark</p>
</li>
<li>
<p>Spark's notion of Resilient Distributed Datasets(RDDs). RDDs represent immutable dataset that can be: </p>
</li>
<li>reused across multi-stage operations.</li>
<li>partitioned across multiple machines.</li>
<li>automatically reconstructed if a partition is lost.</li>
</ul>
<p>to address the pain points that scientists and researchers endure during model evaluation processes. </p>
<p>Examples of these pain points include:</p>
<ul>
<li>Temporal and Zonal averaging of data</li>
<li>Computation of climatologies</li>
<li>Pre-processing of CMIP data such as:</li>
<li>Regridding </li>
<li>Variable clustering (min/max)</li>
<li>calendar harmonizing</li>
</ul>
<h2 id="whats-apache-spark">What's Apache Spark?<a class="headerlink" href="#whats-apache-spark" title="Permanent link">&para;</a></h2>
<ul>
<li>
<p>Apache Spark is an open source cluster computing framework</p>
<ul>
<li>
<p>It was developed at UCB AMPLab, 2014 v1.0, 2016 v.2</p>
<ul>
<li>Actively developed, 1086 contributors, 19, 788 commits (As of June 5, 2017)</li>
</ul>
</li>
<li>
<p>Productive programming interface</p>
<ul>
<li>6 vs 28 lines of code compare to hadoop mapreduce</li>
</ul>
</li>
<li>
<p>Implicit data parallelism</p>
</li>
<li>Fault-tolerance</li>
</ul>
</li>
<li>
<p>Spark for Data-intensive Computing</p>
<ul>
<li>Streaming processing</li>
<li>SQL</li>
<li>Machine Learning, MLlib</li>
<li>Graph Processing</li>
</ul>
</li>
</ul>
<h2 id="porting-apache-spark-software-stack-on-hpc">Porting Apache Spark software stack on HPC<a class="headerlink" href="#porting-apache-spark-software-stack-on-hpc" title="Permanent link">&para;</a></h2>
<ul>
<li>
<p>Advantages of Porting Spark onto HPC</p>
<ul>
<li>A more productive API for data-intensive computing</li>
<li>Relieve the users from:<ul>
<li>concurrency control</li>
<li>communication</li>
<li>memory management with traditional MPI model</li>
</ul>
</li>
<li>Embarrassingly parallel computing, <code class="codehilite">data.map(func)</code></li>
<li>Fault tolerance, <code class="codehilite">recompute()</code></li>
</ul>
</li>
<li>
<p>HPC applications often rely on hierarchical data formats to organize files and datasets. <strong>However, accessing data stored in HDF/netCDF files is not natively supported in Spark.</strong> </p>
</li>
<li>
<p>Reasons of lack of netCDF/HDF support in Spark include:</p>
<ul>
<li>Lack of an API in Spark to directly load or sub-select HDF/netCDF datasets into its in-memory data structures.</li>
<li>HDF/netCDF have a deep hierarchy, which cannot simply be treated as a sequence of bytes nor be evenly divided.</li>
<li>GPFS file system is not well tuned for SPARK I/O and vice versa.</li>
</ul>
</li>
</ul>
<h2 id="data-in-spark">Data in Spark<a class="headerlink" href="#data-in-spark" title="Permanent link">&para;</a></h2>
<p><strong>Resilient Distributed Datasets(RDDs)</strong> are:</p>
<ul>
<li>
<p>The primary abstraction in Spark</p>
<ul>
<li>Immutable(Read-Only) once constructed</li>
<li>Spark tracks lineage information to efficiently recompute lost data</li>
<li>Enable operations on collection of elements in parallel</li>
</ul>
</li>
<li>
<p>You construct RDDs</p>
<ul>
<li>by parallelizing existing Python collections (lists)</li>
<li>by transforming an existing RDDs</li>
<li>from files in HDFS or any other storage system (glade in case of Yellowstone and Cheyenne)</li>
</ul>
</li>
<li>
<p>The programmer needs to specify the number of partitions for an RDD or the default value is used if unspecified.</p>
</li>
</ul>
<p><img alt="Partitioning" src="https://i.imgur.com/zaOQIQY.jpg" /></p>
<p><em>Image Courtesy: BerkeleyX-CS100.1x-Big-Data-with-Apache-Spark</em></p>
<p>There are two types of operations on RDDs: <strong>Transformations</strong> and <strong>Actions</strong>.</p>
<ul>
<li><strong>Transformations</strong> are lazy in a sense that they are not computed immediately</li>
<li>Transformed RDD is executed when action runs on it.</li>
<li>RDDs can be persisted(cached) in memory or disk.</li>
</ul>
<p><strong>Working with RDDs</strong>:</p>
<ul>
<li>Create an RDD from a data source</li>
<li>Apply transformations to an RDD: <code class="codehilite"><span class="na">.map</span><span class="p">(...)</span></code></li>
<li>Apply actions to an RDD: <code class="codehilite"><span class="na">.collect</span><span class="p">()</span></code>, <code class="codehilite"><span class="na">.count</span><span class="p">()</span></code></li>
</ul>
<p><img alt="" src="https://i.imgur.com/iqvUJV5.jpg" /></p>
<p><img alt="" src="https://i.imgur.com/EuyK62Q.jpg" /></p>
<p><em>Image Courtesy: BerkeleyX-CS100.1x-Big-Data-with-Apache-Spark</em></p>
<h2 id="data-in-hdfnetcdf">Data in HDF/netCDF<a class="headerlink" href="#data-in-hdfnetcdf" title="Permanent link">&para;</a></h2>
<ul>
<li>Hierarchical Data Format v5
<img alt="" src="https://i.imgur.com/gFC9CAp.jpg" /></li>
</ul>
<h2 id="support-hdfnetcdf-in-spark-2x-series">Support HDF/netCDF in Spark 2.x Series<a class="headerlink" href="#support-hdfnetcdf-in-spark-2x-series" title="Permanent link">&para;</a></h2>
<ul>
<li>
<p>What does Spark have in reading various data formats?</p>
<ul>
<li>Textfile: <code class="codehilite">sc.textFile()</code> or <code class="codehilite">spark.read.load(&quot;filename.txt&quot;, format=&quot;txt&quot;)</code></li>
<li>Parquet: <code class="codehilite">spark.read.load(&quot;filename.parquet&quot;, format=&quot;parquet&quot;)</code></li>
<li>Json: <code class="codehilite">spark.read.load(&quot;filename.json&quot;, format=&quot;json&quot;)</code></li>
<li>csv: <code class="codehilite">spark.read.load(&quot;filename.csv&quot;, format=&quot;csv)</code></li>
<li>jdbc: <code class="codehilite">spark.read.load(&quot;filename.jdbc&quot;, format=&quot;jdbc&quot;)</code></li>
<li>orc, libsvm follow the same pattern.</li>
</ul>
</li>
<li>
<p>How about HDF5/netCDF4?:</p>
<ul>
<li>There is no such thing as <code class="codehilite">spark.read.load(&quot;filename.hdf5&quot;, format=&quot;hdf5&quot;)</code> or <code class="codehilite">spark.read.load(&quot;filename.nc&quot;, format=&quot;nc&quot;)</code></li>
</ul>
</li>
<li>
<p>Challenges: Functionality and Performance</p>
<ul>
<li>How to transform an netCDF dataset into an RDD?</li>
<li>How to utilize the netCDF I/O libraries in Spark?</li>
<li>How to enable parallel I/O on HPC?</li>
<li>What is the impact of a parallel filesytem striping like <a href="https://en.wikipedia.org/wiki/IBM_General_Parallel_File_System">GPFS</a>?</li>
<li>What is the effect of Caching on I/O in Spark?</li>
</ul>
</li>
<li>
<p>Any Solution?</p>
<ul>
<li><strong><a href="https://github.com/NCAR/PySpark4Climate">PySpark4Climate Package</a></strong> is a high level library for parsing netCDF data with Apache Spark, for Spark SQL and DataFrames.</li>
</ul>
</li>
</ul>
                
                  
                
              
              
                
              
            </article>
          </div>
        </div>
      </main>
      
        
<footer class="md-footer">
  
    <div class="md-footer-nav">
      <nav class="md-footer-nav__inner md-grid">
        
        
          <a href="installation/yellowstone/" title="Yellowstone" class="md-flex md-footer-nav__link md-footer-nav__link--next" rel="next">
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
              <span class="md-flex__ellipsis">
                <span class="md-footer-nav__direction">
                  Next
                </span>
                Yellowstone
              </span>
            </div>
            <div class="md-flex__cell md-flex__cell--shrink">
              <i class="md-icon md-icon--arrow-forward md-footer-nav__button"></i>
            </div>
          </a>
        
      </nav>
    </div>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-footer-copyright">
        
        powered by
        <a href="http://www.mkdocs.org" title="MkDocs">MkDocs</a>
        and
        <a href="http://squidfunk.github.io/mkdocs-material/" title="Material for MkDocs">
          Material for MkDocs</a>
      </div>
      
        
      
    </div>
  </div>
</footer>
      
    </div>
    
      <script src="./assets/javascripts/application-c35428f87f.js"></script>
      
      
      <script>app.initialize({url:{base:"."}})</script>
      
    
    
      
    
  </body>
</html>